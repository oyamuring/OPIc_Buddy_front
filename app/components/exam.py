# ===== OpenAI + quest.pyë¥¼ ì´ìš©í•œ ìµœì¢… ì˜¤í”½ 15ë¬¸í•­ ìƒì„± (exam ì „ìš©) =====
import json, random
import streamlit as st
from openai import OpenAI

import os, sys

HERE = os.path.dirname(__file__)
PARENT = os.path.abspath(os.path.join(HERE, ".."))        # componentsì˜ ë¶€ëª¨
GRANDP = os.path.abspath(os.path.join(HERE, "..", ".."))  # app/components êµ¬ì¡° ëŒ€ë¹„

for p in (PARENT, GRANDP):
    if p not in sys.path:
        sys.path.insert(0, p)

from quest import build_opic_exam  # quest.pyëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©

from components.survey import (
    LEISURE_MAPPING, HOBBY_MAPPING, SPORT_MAPPING, TRAVEL_MAPPING,
    get_user_profile,  # ì„ íƒ
)

def _to_korean_originals(items_en: list[str]) -> list[str]:
    rev = {}
    rev.update({v: k for k, v in LEISURE_MAPPING.items()})
    rev.update({v: k for k, v in HOBBY_MAPPING.items()})
    rev.update({v: k for k, v in SPORT_MAPPING.items()})
    rev.update({v: k for k, v in TRAVEL_MAPPING.items()})
    return [rev.get(x, x) for x in items_en]


def _parse_level(level_any) -> int:
    """'level_4' / 'ë ˆë²¨ 4' / 4 ëª¨ë‘ í—ˆìš© â†’ 1~6 ì •ìˆ˜ë¡œ ë³€í™˜"""
    if isinstance(level_any, int):
        k = level_any
    else:
        s = str(level_any).lower()
        for token in ["ë ˆë²¨", "level", "lvl", "_"]:
            s = s.replace(token, " ")
        s = s.strip()
        digits = [ch for ch in s if ch.isdigit()]
        k = int(digits[-1]) if digits else 4
    return max(1, min(6, k))

def _level_hint(k: int) -> str:
    table = {
        1: ("Use very simple, short prompts on concrete daily topics. "
            "No multi-part instructions or uncommon vocabulary."),
        2: ("Simple familiar scenarios. One-step prompts. Short sentences."),
        3: ("Basic narratives about routines, preferences, and near past/future."),
        4: ("Everyday scenarios with brief reasons/comparisons; 1â€“2 parts okay."),
        5: ("Richer, multi-part prompts with opinions, causes/effects, examples."),
        6: ("Advanced, multi-part prompts with analysis and hypotheticals."),
    }
    return table[k]

def _openai_json(messages, model="gpt-4o-mini", temperature=0.6, client: OpenAI | None = None) -> dict:
    cli = client or OpenAI()  # OPENAI_API_KEY í•„ìš”
    resp = cli.chat.completions.create(
        model=model,
        messages=messages,
        response_format={"type": "json_object"},
        temperature=temperature,
        top_p=0.9,
    )
    text = resp.choices[0].message.content
    try:
        return json.loads(text)
    except Exception:
        cleaned = text.strip().strip("`")
        b, e = cleaned.find("{"), cleaned.rfind("}")
        if b >= 0 and e > b:
            return json.loads(cleaned[b:e+1])
        raise RuntimeError(f"OpenAI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {text[:200]}...")

def _mk_exam_prompt(level_k: int, db_examples: list[str], user_profile: str | None) -> list[dict[str, str]]:
    system = (
        "You are an expert OPIc (Oral Proficiency Interview - computer) item writer. "
        "You must respond ONLY with a valid JSON object. "                 # â˜… JSON ëª…ì‹œ
        "Schema: {\"questions\": [string, ...]}. No extra text, no markdown."
    )
    payload = {
        "task": "Create exactly 15 OPIc-style questions following the sequence.",
        "sequence_outline": [
            "1: self-introduction (1 question)",
            "2-10: survey-related topics (3 blocks Ã— 3 Q each = 9 questions)",
            "11-13: role-play (3 questions)",
            "14-15: random/general OPIc (2 questions)"
        ],
        "difficulty_hint": _level_hint(level_k),
        "constraints": [
            "One question per line. No numbering, no quotes.",
            "Avoid yes/no-only prompts; elicit responses appropriate to the level.",
            "No duplicates. No references to the prompt/context/system.",
            "Keep questions realistic for OPIc.",
            "Return JSON only with the key 'questions' (array of strings)."  # â˜… JSON ëª…ì‹œ
        ],
        "context_examples_from_db": db_examples[:30],
        "user_profile_hint": user_profile or "",
        "output_format_note": "Respond in JSON like: {\"questions\":[\"...\", \"...\"]}"  # â˜… JSON ëª…ì‹œ
    }
    return [
        {"role": "system", "content": system},
        {"role": "user", "content": json.dumps(payload, ensure_ascii=False)},
    ]


def build_opic_questions_with_openai_from_exam(
    seed: int | None = None,
    model: str = "gpt-4o-mini",
    client: OpenAI | None = None
) -> list[str]:
 
    """
    - OpenAIë¡œ ë ˆë²¨ì— ë§ì¶˜ ìµœì¢… 15ë¬¸í•­ ìƒì„± (ë°±ì—…/í•˜ë“œì½”ë”© ì—†ìŒ; ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸)
    """
    if "survey_data" not in st.session_state or not st.session_state.survey_data:
        raise RuntimeError("ì„¤ë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. surveyë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")

    data = st.session_state.survey_data
    level_any = data.get("self_assessment")  # ì˜ˆ: "level_4" ë˜ëŠ” "ë ˆë²¨ 4"
    level_k = _parse_level(level_any)

    # ì„¤ë¬¸ ì‘ë‹µì—ì„œ ì‚¬ìš©í•  í‚¤ë“¤(activitiesì˜ ì˜ì–´ ë¦¬ìŠ¤íŠ¸)
    acts = st.session_state.survey_data.get("activities", {})
    survey_answers_en = []
    for key in ("leisure", "hobbies", "sports", "travel"):
        vals = acts.get(key, [])
        if isinstance(vals, list):
            survey_answers_en.extend([str(v) for v in vals])

    if not survey_answers_en:
        raise RuntimeError("ì„¤ë¬¸ í™œë™ ì„ íƒì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. Step 4ì—ì„œ í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")

    survey_answers_ko = _to_korean_originals(survey_answers_en)  # â˜… ë³€í™˜
    db_examples = build_opic_exam(survey_answers=survey_answers_ko, seed=seed)

    # ì‚¬ìš©ì ìš”ì•½(ì„ íƒ): survey.pyì˜ get_user_profile()ì´ ìˆë‹¤ë©´ í™œìš©
    try:
        from app.components.survey import get_user_profile  # ê²½ë¡œ í”„ë¡œì íŠ¸ì— ë§ê²Œ
        user_profile = get_user_profile()
    except Exception:
        user_profile = ""

    # OpenAIì— ë ˆë²¨/ì»¨í…ìŠ¤íŠ¸/í”„ë¡œí•„ ë°˜ì˜í•´ ìµœì¢… 15ë¬¸í•­ ìƒì„±
    messages = _mk_exam_prompt(level_k, db_examples, user_profile)
    out = _openai_json(messages, model=model, client=client, temperature=0.6)

    # ë¹ˆ ë¬¸ìì—´ ì œê±°, ì¤‘ë³µ ì œê±°, 15ê°œë§Œ ì‚¬ìš© (í•­ìƒ 15ê°œë¡œ ë§ì¶¤)
    cleaned = []
    seen = set()
    for q in out.get("questions", []):
        if not isinstance(q, str):
            continue
        q = q.strip()
        if not q or q in seen:
            continue
        seen.add(q)
        cleaned.append(q)
        if len(cleaned) == 15:
            break
    # í˜¹ì‹œë¼ë„ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆëŠ” 15ê°œ ì²´í¬ ë° ì˜ˆì™¸ ë°œìƒ ì½”ë“œ ì™„ì „ ì œê±°
    while len(cleaned) < 15:
        cleaned.append("")
    if len(cleaned) > 15:
        cleaned = cleaned[:15]
    return cleaned

def ensure_exam_questions_openai(seed: int | None = None, model: str = "gpt-4o-mini"):
    """ì„¸ì…˜ì— exam_questionsê°€ ì—†ìœ¼ë©´ ìƒì„±í•´ì„œ ë„£ëŠ”ë‹¤."""
    if st.session_state.get("exam_questions"):
        return
    client = OpenAI()
    qs = build_opic_questions_with_openai_from_exam(seed=seed, model=model, client=client)
    st.session_state.exam_questions = qs

    # â˜… ê¸¸ì´ ë§ì¶° ë‹µì•ˆ/ì¸ë±ìŠ¤ ì´ˆê¸°í™”
    st.session_state.exam_answers = [""] * len(qs)
    st.session_state.exam_idx = 0

def show_exam():

    qs = st.session_state.get("exam_questions", [])
    if not qs:
        st.error("ì‹œí—˜ ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        return

    # ===== ê°œë°œì ëª¨ë“œ (ë©”ì¸ í™”ë©´) =====
    dev_mode = st.toggle("ê°œë°œì ëª¨ë“œ", value=False, key="dev_mode_main")
    if dev_mode:
        st.markdown("---")
        st.subheader("[ê°œë°œìëª¨ë“œ] ì‚¬ìš©ìê°€ ì„ íƒí•œ Survey ë°ì´í„°")
        st.json(st.session_state.get("survey_data", {}))
        st.subheader("[ê°œë°œìëª¨ë“œ] OpenAIê°€ ìƒì„±í•œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸")
        st.write(qs)
        st.markdown("---")

    if ("exam_answers" not in st.session_state
            or not isinstance(st.session_state.exam_answers, list)
            or len(st.session_state.exam_answers) != len(qs)):
        st.session_state.exam_answers = [""] * len(qs)

    if "exam_idx" not in st.session_state:
        st.session_state.exam_idx = 0

    idx = st.session_state.exam_idx
    if idx < 0 or idx >= len(qs):
        idx = 0
        st.session_state.exam_idx = 0

    # ===== ìƒë‹¨ ì§„í–‰ ë°” =====
    progress = (idx + 1) / len(qs)
    st.markdown(
        f"""
        <div style='margin-bottom: 8px; margin-top: 2px;'>
            <div style='width: 100%; height: 7px; background: #f3f4f6; border-radius: 5px; position: relative; overflow: hidden;'>
                <div style='height: 100%; width: {progress*100:.1f}%; background: linear-gradient(90deg, #3b82f6 60%, #60a5fa 100%); border-radius: 5px; transition: width 0.4s;'></div>
            </div>
        </div>
        <div style='font-size: 1.08rem; font-weight: 600; color: #222; margin-bottom: 8px;'>
            Question {idx + 1} / {len(qs)}
        </div>
        """,
        unsafe_allow_html=True
    )



    from app.utils.voice_utils import VoiceManager, unified_answer_input
    voice_manager = VoiceManager()

    # ë¬¸ì œ ì˜¤ë””ì˜¤ë¥¼ í•­ìƒ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ì¦‰ì‹œ ì¬ìƒ
    audio_bytes = voice_manager.text_to_speech(qs[idx])
    st.session_state[f"audio_bytes_{idx}"] = audio_bytes

    st.audio(audio_bytes, format='audio/mp3', start_time=0)
    st.success("ë¬¸ì œë¥¼ ì¬ìƒí•©ë‹ˆë‹¤!")

    # ===== ë¬¸ì œ í…ìŠ¤íŠ¸ ë³´ê¸° í† ê¸€ =====
    show_text = st.toggle("ğŸ“ ë¬¸ì œ í…ìŠ¤íŠ¸ ë³´ê¸°", value=False, key=f"show_text_{idx}")
    if show_text:
        st.markdown(f"<div style='font-size:1.18rem; font-weight:600; color:#222;'>{qs[idx]}</div>", unsafe_allow_html=True)
        st.markdown("<div style='height: 8px'></div>", unsafe_allow_html=True)

    # ===== ë‹µë³€ ì…ë ¥ (ìŒì„±+í…ìŠ¤íŠ¸ í†µí•©) =====
    from app.utils.voice_utils import auto_convert_audio_if_needed
    answer = unified_answer_input(idx, qs[idx])
    # í•­ìƒ ìµœì‹  ë‹µë³€ì„ exam_answersì— ì €ì¥
    st.session_state.exam_answers[idx] = answer
    # ìŒì„± íŒŒì¼ë„ ë³„ë„ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬ (í”¼ë“œë°±ì—ì„œ ì¬ìƒìš©)
    if 'answer_audio_files' not in st.session_state:
        st.session_state['answer_audio_files'] = [None] * len(qs)
    audio_key = f"audio_data_{idx}"
    if audio_key in st.session_state:
        st.session_state['answer_audio_files'][idx] = st.session_state[audio_key]

    # ===== ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼ =====
    col1, col2 = st.columns([1,1])
    with col1:
        if st.button("â† Back", disabled=(idx == 0)):
            st.session_state.exam_idx -= 1
            st.rerun()
    with col2:
        if idx == len(qs) - 1:
            # ë§ˆì§€ë§‰ ë¬¸ì œ: Finish
            if st.button("Finish"):
                # ë§ˆì§€ë§‰ ë‹µë³€ë„ ìë™ ë³€í™˜ ì‹œë„ (ìŒì„±ë§Œ ìˆê³  í…ìŠ¤íŠ¸ ì—†ì„ ë•Œ)
                final_answer = auto_convert_audio_if_needed(idx)
                st.session_state.exam_answers[idx] = final_answer
                # ìŒì„± íŒŒì¼ë„ ì €ì¥
                if audio_key in st.session_state:
                    st.session_state['answer_audio_files'][idx] = st.session_state[audio_key]
                st.session_state.stage = "feedback"
                st.rerun()
        else:
            if st.button("Next â†’"):
                # ë‹¤ìŒ ë¬¸ì œë¡œ ë„˜ì–´ê°ˆ ë•Œë„ ìë™ ë³€í™˜ ì‹œë„
                final_answer = auto_convert_audio_if_needed(idx)
                st.session_state.exam_answers[idx] = final_answer
                # ìŒì„± íŒŒì¼ë„ ì €ì¥
                if audio_key in st.session_state:
                    st.session_state['answer_audio_files'][idx] = st.session_state[audio_key]
                st.session_state.exam_idx += 1
                st.rerun()

