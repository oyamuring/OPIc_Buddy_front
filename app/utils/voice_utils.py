"""
OPIc ì‹œí—˜ìš© í†µí•© ìŒì„± ê¸°ëŠ¥ ìœ í‹¸ë¦¬í‹°
- TTS: OpenAI TTS (mp3)
- STT: OpenAI Whisper API (BytesIO ê¸°ë°˜)
- í†µí•© ë‹µë³€ ì…ë ¥ (ìŒì„± + í…ìŠ¤íŠ¸)
"""

import io
import os
import streamlit as st
from openai import OpenAI


class VoiceManager:
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        self.openai_client = OpenAI(api_key=api_key) if api_key else None

    def text_to_speech(self, text: str, lang: str = 'en') -> bytes:
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±(mp3)ìœ¼ë¡œ ë³€í™˜ (OpenAI TTS API)"""
        if not self.openai_client:
            st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ì–´ TTS ì‚¬ìš© ë¶ˆê°€")
            return None
        try:
            resp = self.openai_client.audio.speech.create(
                model="tts-1",
                input=text,
                voice="alloy",  # ì„ íƒ: alloy, echo, fable, onyx, nova, shimmer
                response_format="mp3"
            )
            return resp.content
        except Exception as e:
            st.error(f"TTS ì˜¤ë¥˜: {e}")
            return None

    def speech_to_text(self, audio_bytes: bytes) -> str:
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (OpenAI Whisper API, BytesIO ê¸°ë°˜)"""
        if not self.openai_client:
            st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ì–´ STT ì‚¬ìš© ë¶ˆê°€")
            return "[Voice recording - STT unavailable]"
        try:
            audio_file = io.BytesIO(audio_bytes)
            audio_file.name = "input.wav"  # í™•ì¥ì í•„ìˆ˜
            transcript = self.openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="en"
            )
            return transcript.text.strip()
        except Exception as e:
            st.error(f"STT ì˜¤ë¥˜: {e}")
            return f"[Voice recording - STT error: {e}]"


def unified_answer_input(question_idx: int, question_text: str) -> str:
    """í†µí•©ëœ ë‹µë³€ ì…ë ¥ UI (ìŒì„± + í…ìŠ¤íŠ¸)"""
    voice_manager = VoiceManager()
    answer_key = f"ans_{question_idx}"
    current_answer = st.session_state.get(answer_key, "")

    tab1, tab2 = st.tabs(["ğŸ¤ ìŒì„± ë‹µë³€", "ğŸ’¬ í…ìŠ¤íŠ¸ ë‹µë³€"])
    final_answer = ""

    # ğŸ¤ ìŒì„± ì…ë ¥ íƒ­
    with tab1:
        st.markdown("#### ğŸ¤ ìŒì„±ìœ¼ë¡œ ë‹µë³€í•˜ê¸° (ìµœëŒ€ 60ì´ˆ)")

        audio_data_key = f"audio_data_{question_idx}"
        stt_flag_key = f"stt_done_{question_idx}"

        audio_data = st.session_state.get(audio_data_key)
        if audio_data:
            st.audio(audio_data, format="audio/wav")

        audio_value = st.audio_input(
            "ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒí•˜ì„¸ìš”",
            key=f"audio_input_{question_idx}"
        )

        if audio_value is not None and not st.session_state.get(stt_flag_key):
            st.success("ğŸµ ìŒì„±ì´ ë…¹ìŒë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.session_state[audio_data_key] = audio_value.getvalue()
            st.audio(audio_value, format="audio/wav")
            with st.spinner("ğŸ”„ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                transcript = voice_manager.speech_to_text(audio_value.getvalue())
            if transcript and not transcript.startswith("[Voice recording"):
                final_answer = transcript
                st.session_state[answer_key] = final_answer
                st.session_state[stt_flag_key] = True
                st.rerun()
            else:
                st.error("âš ï¸ ìŒì„± ë³€í™˜ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        elif audio_value is None and st.session_state.get(stt_flag_key):
            st.session_state[stt_flag_key] = False

    # ğŸ’¬ í…ìŠ¤íŠ¸ ì…ë ¥ íƒ­
    with tab2:
        st.markdown("#### ğŸ’¬ í…ìŠ¤íŠ¸ë¡œ ë‹µë³€í•˜ê¸°")
        text_answer = st.text_area(
            "Your answer (English):",
            value=current_answer if not current_answer.startswith("[Voice") else "",
            key=f"text_input_{question_idx}",
            height=150
        )
        if text_answer.strip():
            final_answer = text_answer.strip()
            st.session_state[answer_key] = final_answer

    return st.session_state.get(answer_key, "")


def auto_convert_audio_if_needed(question_idx: int) -> str:
    """Next ë²„íŠ¼ í´ë¦­ ì‹œ ìë™ STT ë³€í™˜"""
    answer_key = f"ans_{question_idx}"
    audio_key = f"audio_data_{question_idx}"

    existing_answer = st.session_state.get(answer_key, "")
    if existing_answer and not existing_answer.startswith("[Voice recording"):
        return existing_answer

    audio_data = st.session_state.get(audio_key)
    if audio_data:
        try:
            voice_manager = VoiceManager()
            transcript = voice_manager.speech_to_text(audio_data)
            if transcript and not transcript.startswith("[Voice recording"):
                st.session_state[answer_key] = transcript
                st.session_state[f"audio_{question_idx}"] = audio_data
                return transcript
            return "[Voice recording - conversion failed]"
        except Exception as e:
            return f"[Voice recording - STT error: {e}]"

    return existing_answer


def display_tts_button(text, message_index=0):
    """í…ìŠ¤íŠ¸ â†’ ìŒì„± ë²„íŠ¼"""
    col1, col2 = st.columns([2.5, 1.5])
    with col2:
        unique_key = f"tts_{message_index}_{hash(text)}"
        if st.button("ğŸ”Š ìŒì„±ìœ¼ë¡œ ë“£ê¸°", key=unique_key):
            voice_manager = VoiceManager()
            audio_data = voice_manager.text_to_speech(text)
            if audio_data:
                st.audio(audio_data, format="audio/mp3")
